import requests
from bs4 import BeautifulSoup
from datetime import datetime
import os

def get_news():
    news_list = []
    headers = {'User-Agent': 'Mozilla/5.0'} # Siteye "ben bir tarayƒ±cƒ±yƒ±m" diyoruz

    # 1. Kaynak: BleepingComputer (Siber G√ºvenlik)
    try:
        r = requests.get("https://www.bleepingcomputer.com/", headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        # Sadece ana haber listesindeki h2 ba≈ülƒ±klarƒ±nƒ± alƒ±yoruz
        cyber_items = soup.find_all('h2', limit=5) 
        for n in cyber_items:
            title = n.text.strip()
            if len(title) > 20: # Kƒ±sa buton isimlerini (Giri≈ü, Kayƒ±t vb.) elemek i√ßin
                news_list.append(f"üõ°Ô∏è [Siber G√ºvenlik]: {title}")
                if len([x for x in news_list if "üõ°Ô∏è" in x]) >= 2: break
    except: pass

    # 2. Kaynak: HackerNoon (Yapay Zeka)
    try:
        r = requests.get("https://hackernoon.com/tagged/ai", headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        # HackerNoon'da haber ba≈ülƒ±klarƒ± genellikle h2 i√ßindeki linklerdedir
        ai_items = soup.find_all('h2', limit=10)
        count = 0
        for n in ai_items:
            title = n.text.strip()
            # "A√ßƒ±k Mod", "Karanlƒ±k Mod" gibi kelimeleri engelliyoruz
            if len(title) > 25 and "Mod" not in title:
                news_list.append(f"ü§ñ [Yapay Zeka]: {title}")
                count += 1
                if count >= 2: break
    except: pass

    # Sonu√ßlarƒ± Kaydet
    date_str = datetime.now().strftime('%Y-%m-%d')
    content = f"--- {date_str} Teknoloji G√ºndemi ---\n\n"
    content += "\n".join(news_list) if news_list else "‚ö†Ô∏è Haberler √ßekilemedi, se√ßiciler g√ºncellenmeli."
    
    if not os.path.exists('logs'): os.makedirs('logs')
    with open(f"logs/news_{date_str}.txt", "w", encoding="utf-8") as f:
        f.write(content)

if __name__ == "__main__":
    get_news()
